import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import warnings
import os
from functools import lru_cache

warnings.filterwarnings("ignore")

# =========================
# CONFIGURA√á√ÉO DA P√ÅGINA
# =========================
st.set_page_config(
    page_title="FAO Agrifood Carbon Market",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================
# CONSTANTES E CONFIGURA√á√ïES
# =========================
SHEET_CONFIG = {
    "README": {"description": "Documenta√ß√£o e metadados do dataset"},
    "1. Standards": {"description": "Padr√µes e registros de carbono", "main_column": "Name of standard/registry/platform"},
    "2. Platforms": {"description": "Plataformas de mercado de carbono", "main_column": "Platform"},
    "3. Methodologies": {"description": "Metodologias de c√°lculo de carbono", "main_column": "Data sourced from methodology document (see reference in column AD)"},
    "4. Agriculture": {"description": "Projetos agr√≠colas", "has_yearly_data": True, "credit_column_pattern": "Credits issued by vintage"},
    "5. Agroforestry-AR & Grassland": {"description": "Projetos agroflorestais e pastagens", "has_yearly_data": True},
    "6. Energy and Other": {"description": "Projetos de energia e outros", "has_yearly_data": True},
    "7. Plan Vivo, Acorn, Social C": {"description": "Padr√µes espec√≠ficos", "main_column": "Standard"},
    "8. Puro.earth": {"description": "Projetos Puro.earth", "main_column": "Unnamed: 0"},
    "9. Nori and BCarbon": {"description": "Projetos Nori e BCarbon", "main_column": "Standard"}
}

# =========================
# LOAD DO EXCEL LOCAL (GITHUB)
# =========================
@st.cache_data(ttl=86400, show_spinner="Carregando dataset...")
def load_data():
    file_path = "Dataset.xlsx"
    
    if not os.path.exists(file_path):
        st.error("‚ùå Arquivo 'Dataset.xlsx' n√£o encontrado!")
        st.info("Certifique-se de que o arquivo est√° na raiz do diret√≥rio.")
        return None, None
    
    try:
        excel = pd.ExcelFile(file_path, engine='openpyxl')
        data = {}
        
        for sheet in excel.sheet_names:
            try:
                df = excel.parse(sheet, header=0)
                
                # Limpeza b√°sica de colunas
                df = df.dropna(axis=1, how='all')  # Remove colunas completamente vazias
                df.columns = [str(col).strip() for col in df.columns]  # Limpa nomes de colunas
                
                # Identifica primeira linha como header se necess√°rio
                if df.iloc[0].isnull().all() or df.shape[0] > 0:
                    # Verifica se a primeira linha parece ser header duplicado
                    first_row_values = df.iloc[0].astype(str).str.lower().tolist()
                    header_indicators = ['project', 'name', 'standard', 'data', 'credit', 'method']
                    if any(indicator in str(val) for val in first_row_values for indicator in header_indicators):
                        # Usa a primeira linha como header e remove ela
                        df.columns = df.iloc[0]
                        df = df[1:].reset_index(drop=True)
                
                data[sheet] = df
            except Exception as e:
                st.warning(f"Aviso: Erro ao processar aba '{sheet}': {str(e)[:100]}")
                data[sheet] = pd.DataFrame()
        
        if not data:
            st.error("Nenhuma aba p√¥de ser carregada do arquivo Excel.")
            return None, None
            
        return data, list(data.keys())
    except Exception as e:
        st.error(f"Erro cr√≠tico ao carregar arquivo: {e}")
        return None, None

# =========================
# FUN√á√ïES DE AN√ÅLISE AVAN√áADA
# =========================
def analyze_sheet_structure(df, sheet_name):
    """Analisa a estrutura da aba e fornece insights espec√≠ficos"""
    insights = []
    
    if df.empty:
        insights.append("‚ö†Ô∏è DataFrame vazio")
        return insights
    
    # Informa√ß√µes b√°sicas
    insights.append(f"üìä **Formato**: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
    
    # An√°lise de tipos de dados
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    text_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    insights.append(f"üî¢ **Colunas num√©ricas**: {len(numeric_cols)}")
    insights.append(f"üìù **Colunas de texto**: {len(text_cols)}")
    
    # An√°lise de valores ausentes
    missing_percent = df.isnull().mean() * 100
    high_missing = missing_percent[missing_percent > 50].index.tolist()
    
    if high_missing:
        if len(high_missing) > 5:
            insights.append(f"‚ö†Ô∏è **{len(high_missing)} colunas t√™m mais de 50% de valores ausentes**")
        else:
            for col in high_missing[:5]:
                insights.append(f"‚ö†Ô∏è **{col}**: {missing_percent[col]:.1f}% ausente")
    
    # Detec√ß√£o de colunas com dados temporais/anuais
    year_patterns = ['year', 'vintage', 'issued', 'retired', '20', '19']
    year_cols = [col for col in df.columns if any(pattern in str(col).lower() for pattern in year_patterns) 
                and df[col].dtype in [np.int64, np.float64]]
    
    if year_cols and len(year_cols) > 5:
        insights.append(f"üìÖ **Detectadas {len(year_cols)} colunas com dados anuais**")
    
    # Detec√ß√£o de colunas com valores √∫nicos (potenciais chaves)
    unique_counts = df.nunique()
    high_unique = unique_counts[unique_counts == df.shape[0]].index.tolist()
    if high_unique:
        insights.append(f"üîë **Colunas com valores √∫nicos**: {', '.join(high_unique[:3])}")
    
    return insights

def extract_yearly_data(df, sheet_name):
    """Extrai dados anuais de colunas que parecem conter dados temporais"""
    yearly_data = {}
    
    # Padr√µes de nomes de colunas que podem conter anos
    year_pattern = r'(19\d{2}|20\d{2})'
    
    for col in df.columns:
        col_str = str(col)
        # Procura por padr√µes de ano no nome da coluna
        if any(x in col_str.lower() for x in ['20', '19', 'vintage', 'issued', 'retired']):
            try:
                # Tenta extrair o ano do nome da coluna
                year_match = pd.Series([col_str]).str.extract(f'({year_pattern})')
                if not year_match.isna().all().all():
                    year = int(year_match.iloc[0, 0])
                    # Verifica se a coluna √© num√©rica
                    if pd.api.types.is_numeric_dtype(df[col]):
                        yearly_data[year] = {
                            'value': df[col].sum(),
                            'non_zero_count': (df[col] > 0).sum(),
                            'mean': df[col].mean()
                        }
            except:
                continue
    
    return yearly_data

def create_projects_summary(df, sheet_name):
    """Cria um resumo dos projetos baseado na estrutura da aba"""
    summary = {}
    
    if sheet_name in ["4. Agriculture", "5. Agroforestry-AR & Grassland", "6. Energy and Other"]:
        # Identifica coluna de nome do projeto
        project_cols = [col for col in df.columns if 'name' in str(col).lower() or 'project' in str(col).lower()]
        
        if project_cols and not df.empty:
            project_col = project_cols[0]
            summary['total_projects'] = df[project_col].nunique()
            summary['sample_projects'] = df[project_col].dropna().unique()[:5].tolist()
            
            # Tenta identificar coluna de padr√£o/registro
            registry_cols = [col for col in df.columns if 'registry' in str(col).lower() or 'standard' in str(col).lower()]
            if registry_cols:
                registry_col = registry_cols[0]
                summary['registries'] = df[registry_col].value_counts().head().to_dict()
    
    return summary

def enhanced_smart_insights(df, sheet_name):
    """Insights avan√ßados baseados na estrutura espec√≠fica de cada aba"""
    insights = []
    
    if df.empty:
        insights.append("üì≠ **DataFrame vazio** - Nenhum dado dispon√≠vel")
        return insights
    
    config = SHEET_CONFIG.get(sheet_name, {})
    
    # Insights espec√≠ficos por tipo de aba
    if "Agriculture" in sheet_name or "Agroforestry" in sheet_name:
        # Procura por colunas de cr√©ditos
        credit_cols = [col for col in df.columns if 'credit' in str(col).lower()]
        if credit_cols:
            insights.append(f"üí∞ **Colunas de cr√©ditos identificadas**: {len(credit_cols)}")
            
            # Tenta encontrar colunas num√©ricas com valores significativos
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                # Encontra coluna com maior soma
                col_sums = df[numeric_cols].sum()
                if not col_sums.empty:
                    max_col = col_sums.idxmax()
                    max_value = col_sums.max()
                    if max_value > 0:
                        insights.append(f"üìà **Maior volume de cr√©ditos**: Coluna '{max_col}' com {max_value:,.0f} unidades")
    
    elif "Methodologies" in sheet_name:
        # An√°lise para aba de metodologias
        insights.append("üî¨ **Aba de metodologias** - Dados t√©cnicos de c√°lculo de carbono")
        
    elif "Standards" in sheet_name or "Platforms" in sheet_name:
        insights.append("üè¢ **Dados institucionais** - Padr√µes e plataformas do mercado")
        
        # Verifica coluna principal
        main_col = config.get('main_column')
        if main_col and main_col in df.columns:
            unique_vals = df[main_col].nunique()
            insights.append(f"üèõÔ∏è **{unique_vals} {main_col.split()[-1]} √∫nicos**")
    
    # An√°lise geral de qualidade
    missing_rate = df.isnull().mean().mean() * 100
    if missing_rate > 30:
        insights.append(f"‚ö†Ô∏è **Alta taxa de valores ausentes**: {missing_rate:.1f}%")
    elif missing_rate < 5:
        insights.append(f"‚úÖ **Dados bem preenchidos**: apenas {missing_rate:.1f}% ausentes")
    
    # Detec√ß√£o de outliers em colunas num√©ricas
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        for col in numeric_cols[:3]:  # Analisa apenas as primeiras 3 colunas
            if df[col].notna().sum() > 10:  # Tem dados suficientes
                q1 = df[col].quantile(0.25)
                q3 = df[col].quantile(0.75)
                iqr = q3 - q1
                outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()
                if outliers > 0:
                    insights.append(f"üîç **Poss√≠veis outliers em '{col}'**: {outliers} valores")
    
    return insights

# =========================
# FUN√á√ïES DE VISUALIZA√á√ÉO
# =========================
def create_yearly_trend_chart(yearly_data):
    """Cria gr√°fico de tend√™ncia anual"""
    if not yearly_data:
        return None
    
    years = sorted(yearly_data.keys())
    values = [yearly_data[year]['value'] for year in years]
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=years, 
        y=values,
        mode='lines+markers',
        name='Cr√©ditos',
        line=dict(color='#2ecc71', width=3),
        marker=dict(size=8)
    ))
    
    fig.update_layout(
        title='Tend√™ncia Anual de Cr√©ditos',
        xaxis_title='Ano',
        yaxis_title='Total de Cr√©ditos',
        template='plotly_white',
        hovermode='x unified'
    )
    
    return fig

def create_data_quality_chart(df):
    """Cria gr√°fico de qualidade dos dados"""
    missing_percent = df.isnull().mean() * 100
    top_missing = missing_percent.sort_values(ascending=False).head(10)
    
    if len(top_missing) == 0:
        return None
    
    fig = px.bar(
        x=top_missing.values,
        y=top_missing.index,
        orientation='h',
        title='Top 10 Colunas com Mais Valores Ausentes',
        labels={'x': '% Ausente', 'y': 'Coluna'},
        color=top_missing.values,
        color_continuous_scale='RdYlGn_r'
    )
    
    fig.update_layout(showlegend=False)
    return fig

def create_project_distribution_chart(df, sheet_name):
    """Cria gr√°fico de distribui√ß√£o de projetos"""
    if sheet_name in SHEET_CONFIG:
        config = SHEET_CONFIG[sheet_name]
        main_col = config.get('main_column')
        
        if main_col and main_col in df.columns:
            value_counts = df[main_col].value_counts().head(10)
            
            if len(value_counts) > 0:
                fig = px.bar(
                    x=value_counts.values,
                    y=value_counts.index,
                    orientation='h',
                    title=f'Top 10 {main_col}',
                    labels={'x': 'Contagem', 'y': main_col},
                    color=value_counts.values,
                    color_continuous_scale='Viridis'
                )
                return fig
    
    return None

# =========================
# APP PRINCIPAL
# =========================
def main():
    st.title("üå± FAO Agrifood Carbon Market Dashboard")
    st.markdown("### An√°lise Interativa do Mercado Volunt√°rio de Carbono Agr√≠cola")
    
    # ---------- LOAD ----------
    with st.spinner("Carregando dados do dataset FAO..."):
        dataframes, sheets = load_data()
    
    if dataframes is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados!")
        st.info("Verifique se o arquivo 'Dataset.xlsx' est√° na raiz do projeto.")
        st.stop()
    
    # ---------- SIDEBAR ----------
    with st.sidebar:
        st.header("üìÇ Navega√ß√£o")
        
        selected_sheet = st.selectbox(
            "Selecione a aba:",
            sheets,
            format_func=lambda x: f"{x} - {SHEET_CONFIG.get(x, {}).get('description', 'Sem descri√ß√£o')}"
        )
        
        st.markdown("---")
        st.header("üöÄ Ferramentas de An√°lise")
        
        show_summary = st.toggle("üìä Vis√£o Geral do Dataset", True)
        show_insights = st.toggle("üß† Insights Autom√°ticos", True)
        show_quality = st.toggle("üìà An√°lise de Qualidade", False)
        show_yearly = st.toggle("üìÖ Dados Temporais", False)
        
        st.markdown("---")
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        max_rows = st.slider("M√°ximo de linhas para visualizar:", 10, 500, 100)
        auto_clean = st.toggle("Limpeza autom√°tica de dados", False)
    
    # ---------- VIS√ÉO GERAL ----------
    if show_summary:
        st.subheader("üìä Vis√£o Geral do Dataset")
        
        # M√©tricas principais
        total_rows = sum(df.shape[0] for df in dataframes.values() if not df.empty)
        total_cols = sum(df.shape[1] for df in dataframes.values() if not df.empty)
        total_sheets = len([df for df in dataframes.values() if not df.empty])
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Total de Abas", total_sheets)
        col2.metric("Total de Registros", f"{total_rows:,}")
        col3.metric("Total de Colunas", total_cols)
        col4.metric("Tamanho Aprox.", f"{total_rows * total_cols / 1000:.0f}K c√©lulas")
        
        # Tabela de resumo por aba
        summary_data = []
        for name, df in dataframes.items():
            if not df.empty:
                numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
                missing_percent = df.isnull().mean().mean() * 100
                memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
                
                summary_data.append({
                    "Aba": name,
                    "Linhas": df.shape[0],
                    "Colunas": df.shape[1],
                    "Num√©ricas": numeric_cols,
                    "% Nulos": f"{missing_percent:.1f}%",
                    "Mem√≥ria (MB)": f"{memory_mb:.1f}",
                    "Descri√ß√£o": SHEET_CONFIG.get(name, {}).get("description", "-")
                })
        
        if summary_data:
            st.dataframe(pd.DataFrame(summary_data), use_container_width=True, height=300)
    
    # ---------- ABA SELECIONADA ----------
    df = dataframes[selected_sheet]
    
    if df.empty:
        st.warning(f"A aba '{selected_sheet}' est√° vazia ou n√£o p√¥de ser carregada.")
        return
    
    st.divider()
    st.header(f"üìÑ {selected_sheet}")
    st.caption(SHEET_CONFIG.get(selected_sheet, {}).get("description", ""))
    
    # Insights avan√ßados
    if show_insights:
        with st.expander("üß† Insights Inteligentes", expanded=True):
            insights = enhanced_smart_insights(df, selected_sheet)
            for insight in insights:
                st.write(f"‚Ä¢ {insight}")
            
            # An√°lise de estrutura
            structure_insights = analyze_sheet_structure(df, selected_sheet)
            if structure_insights:
                st.markdown("---")
                st.markdown("**An√°lise de Estrutura:**")
                for insight in structure_insights:
                    st.write(f"‚Ä¢ {insight}")
    
    # TABS PRINCIPAIS
    tab1, tab2, tab3, tab4 = st.tabs(["üìã Dados", "üìà Visualiza√ß√µes", "üîç An√°lises", "üíæ Exportar"])
    
    with tab1:
        st.subheader("Visualiza√ß√£o dos Dados")
        
        # Filtros b√°sicos
        col_filter1, col_filter2 = st.columns(2)
        with col_filter1:
            show_columns = st.multiselect(
                "Selecionar colunas:",
                df.columns.tolist(),
                default=df.columns.tolist()[:10] if len(df.columns) > 10 else df.columns.tolist()
            )
        
        with col_filter2:
            if len(df) > 100:
                n_rows = st.slider("N√∫mero de linhas:", 10, min(500, len(df)), 100)
            else:
                n_rows = len(df)
        
        # Dataframe filtrado
        filtered_df = df[show_columns].head(n_rows) if show_columns else df.head(n_rows)
        st.dataframe(filtered_df, use_container_width=True, height=400)
        
        # Estat√≠sticas r√°pidas
        with st.expander("üìä Estat√≠sticas Descritivas"):
            numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                st.dataframe(filtered_df[numeric_cols].describe().round(2), use_container_width=True)
            else:
                st.info("Nenhuma coluna num√©rica para estat√≠sticas.")
    
    with tab2:
        st.subheader("Visualiza√ß√µes Gr√°ficas")
        
        viz_col1, viz_col2 = st.columns(2)
        
        with viz_col1:
            # Gr√°fico 1: Distribui√ß√£o de valores num√©ricos
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                selected_num_col = st.selectbox("Selecione coluna num√©rica:", numeric_cols)
                
                if pd.api.types.is_numeric_dtype(df[selected_num_col]):
                    fig = px.histogram(
                        df, 
                        x=selected_num_col,
                        title=f"Distribui√ß√£o de {selected_num_col}",
                        nbins=50,
                        color_discrete_sequence=['#2ecc71'],
                        opacity=0.8
                    )
                    fig.update_layout(bargap=0.1)
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Nenhuma coluna num√©rica para histograma.")
        
        with viz_col2:
            # Gr√°fico 2: Qualidade dos dados
            if show_quality:
                quality_fig = create_data_quality_chart(df)
                if quality_fig:
                    st.plotly_chart(quality_fig, use_container_width=True)
                else:
                    st.info("Informa√ß√µes de qualidade n√£o dispon√≠veis.")
            
            # Gr√°fico 3: Distribui√ß√£o de projetos
            project_fig = create_project_distribution_chart(df, selected_sheet)
            if project_fig:
                st.plotly_chart(project_fig, use_container_width=True)
        
        # Gr√°fico de tend√™ncia anual (se aplic√°vel)
        if show_yearly:
            yearly_data = extract_yearly_data(df, selected_sheet)
            if yearly_data:
                trend_fig = create_yearly_trend_chart(yearly_data)
                if trend_fig:
                    st.plotly_chart(trend_fig, use_container_width=True)
    
    with tab3:
        st.subheader("An√°lises Avan√ßadas")
        
        analysis_type = st.radio(
            "Tipo de an√°lise:",
            ["Correla√ß√µes", "Valores Ausentes", "Distribui√ß√£o", "Sum√°rio"]
        )
        
        if analysis_type == "Correla√ß√µes":
            numeric_df = df.select_dtypes(include=[np.number])
            if numeric_df.shape[1] >= 2:
                corr_matrix = numeric_df.corr()
                
                fig = go.Figure(data=go.Heatmap(
                    z=corr_matrix.values,
                    x=corr_matrix.columns,
                    y=corr_matrix.columns,
                    colorscale='RdBu',
                    zmid=0,
                    text=corr_matrix.round(2).values,
                    texttemplate='%{text}',
                    hoverongaps=False
                ))
                
                fig.update_layout(
                    title='Matriz de Correla√ß√£o',
                    width=600,
                    height=600
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Necess√°rias pelo menos 2 colunas num√©ricas para an√°lise de correla√ß√£o.")
        
        elif analysis_type == "Valores Ausentes":
            missing_df = pd.DataFrame({
                'Coluna': df.columns,
                '% Ausente': (df.isnull().mean() * 100).round(2),
                'Total Ausente': df.isnull().sum()
            }).sort_values('% Ausente', ascending=False)
            
            st.dataframe(missing_df, use_container_width=True, height=400)
            
            # Visualiza√ß√£o de missing
            fig = px.bar(
                missing_df.head(20),
                x='% Ausente',
                y='Coluna',
                orientation='h',
                title='Top 20 Colunas com Valores Ausentes'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        elif analysis_type == "Distribui√ß√£o":
            # Distribui√ß√£o de valores √∫nicos
            unique_counts = pd.DataFrame({
                'Coluna': df.columns,
                'Valores √önicos': df.nunique(),
                'Tipo': df.dtypes.astype(str)
            }).sort_values('Valores √önicos', ascending=False)
            
            st.dataframe(unique_counts, use_container_width=True, height=400)
        
        else:  # Sum√°rio
            # Buffer para an√°lise detalhada
            buffer = []
            
            buffer.append(f"### üìã Sum√°rio da Aba: {selected_sheet}")
            buffer.append(f"- **Dimens√µes**: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
            buffer.append(f"- **Mem√≥ria usada**: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
            
            # Tipos de dados
            dtype_counts = df.dtypes.value_counts()
            buffer.append("\n**Tipos de dados:**")
            for dtype, count in dtype_counts.items():
                buffer.append(f"  - {dtype}: {count} colunas")
            
            # Colunas com mais dados
            complete_cols = df.notna().sum().sort_values(ascending=False).head(5)
            buffer.append("\n**Colunas mais completas:**")
            for col, count in complete_cols.items():
                percent = (count / len(df)) * 100
                buffer.append(f"  - {col}: {count} valores ({percent:.1f}%)")
            
            # Exibe o sum√°rio
            st.markdown("\n".join(buffer))
    
    with tab4:
        st.subheader("Exporta√ß√£o de Dados")
        
        export_col1, export_col2 = st.columns(2)
        
        with export_col1:
            export_format = st.radio(
                "Formato de exporta√ß√£o:",
                ["CSV", "Excel", "JSON"]
            )
            
            if export_format == "CSV":
                csv_data = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="üì• Baixar como CSV",
                    data=csv_data,
                    file_name=f"{selected_sheet.replace(' ', '_')}.csv",
                    mime="text/csv"
                )
            
            elif export_format == "Excel":
                # Cria um Excel tempor√°rio
                import io
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name=selected_sheet[:31])
                buffer.seek(0)
                
                st.download_button(
                    label="üì• Baixar como Excel",
                    data=buffer,
                    file_name=f"{selected_sheet.replace(' ', '_')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
            else:  # JSON
                json_data = df.to_json(orient='records', indent=2)
                st.download_button(
                    label="üì• Baixar como JSON",
                    data=json_data,
                    file_name=f"{selected_sheet.replace(' ', '_')}.json",
                    mime="application/json"
                )
        
        with export_col2:
            st.markdown("**Op√ß√µes de exporta√ß√£o:**")
            
            export_all_sheets = st.checkbox("Exportar todas as abas")
            if export_all_sheets:
                st.info("Isso criar√° um arquivo ZIP com todas as abas.")
            
            clean_for_export = st.checkbox("Limpar dados antes de exportar", value=True)
            if clean_for_export:
                st.caption("Remover√° colunas completamente vazias e linhas duplicadas.")
    
    # ---------- RODAP√â ----------
    st.divider()
    
    footer_col1, footer_col2, footer_col3 = st.columns(3)
    
    with footer_col1:
        st.caption(f"üìÖ √öltima atualiza√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
    
    with footer_col2:
        st.caption(f"üìä Dados carregados: {len(dataframes)} abas, {df.shape[0]:,} registros")
    
    with footer_col3:
        st.caption("üåç FAO Agrifood Carbon Market Dataset v1.0")

if __name__ == "__main__":
    main()
